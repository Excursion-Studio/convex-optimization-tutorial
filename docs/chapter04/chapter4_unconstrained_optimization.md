# 第4章 无约束优化算法

## 4.1 一阶方法

一阶方法是仅使用目标函数的一阶导数（梯度）信息来求解优化问题的算法。这类方法计算效率高，适用于大规模优化问题。

### 4.1.1 梯度下降法

梯度下降法是最基本的一阶优化算法，其基本思想是沿着目标函数梯度的负方向（即函数值下降最快的方向）移动，以达到最小化目标函数的目的。

#### 算法步骤

1. 选择初始点 $x_0 \in \mathbb{R}^n$，设置迭代次数 $k=0$。
2. 计算梯度 $g_k = \nabla f(x_k)$。
3. 如果 $\lVert g_k \rVert \leq \epsilon$（$\epsilon$ 是预设的收敛阈值），则停止迭代，输出 $x_k$。
4. 选择步长 $\alpha_k > 0$。
5. 更新迭代点：$x_{k+1} = x_k - \alpha_k g_k$。
6. 令 $k = k + 1$，返回步骤 2。

#### 梯度下降法的数学表达式

梯度下降法的更新规则可以表示为：

$$x_{k+1} = x_k - \alpha_k \nabla f(x_k)$$

其中 $\alpha_k$ 是第 $k$ 次迭代的步长。

#### 梯度下降法的几何解释

梯度下降法的几何意义是：在每一步迭代中，我们沿着当前点的负梯度方向（即函数值下降最快的方向）迈出一定的步长，以期望到达函数值更小的点。

#### 梯度下降法的优缺点

**优点：**
- 算法简单，易于实现。
- 每次迭代的计算量小，仅需计算梯度。
- 适用于大规模优化问题。

**缺点：**
- 收敛速度可能较慢，特别是在接近最优解时。
- 步长的选择对收敛速度影响很大。
- 在非凸优化问题中，可能会陷入局部最优解。

### 4.1.2 步长选择策略

步长的选择是梯度下降法中的关键问题，不同的步长选择策略会影响算法的收敛速度和稳定性。

#### 固定步长

固定步长策略是指在整个迭代过程中使用相同的步长 $\alpha$。这种策略简单，但步长的选择需要经验：步长太小会导致收敛速度慢，步长太大会导致算法不稳定甚至发散。

####  Armijo准则（回溯线搜索）

Armijo准则是一种自适应步长选择策略，其基本思想是从一个较大的初始步长开始，逐渐减小步长，直到满足一定的条件。

Armijo准则的具体步骤如下：

1. 选择初始步长 $\alpha_0 > 0$，参数 $\beta \in (0, 1)$，$\sigma \in (0, 0.5)$。
2. 令 $\alpha = \alpha_0$。
3. 检查是否满足：$f(x_k - \alpha \nabla f(x_k)) \leq f(x_k) - \sigma \alpha \lVert \nabla f(x_k) \rVert^2$。
4. 如果满足，则接受当前步长 $\alpha$；否则，令 $\alpha = \beta \alpha$，返回步骤 3。

Armijo准则保证了步长足够小，使得目标函数值能够充分下降，同时又不会太小导致收敛速度过慢。

#### Wolfe条件

Wolfe条件是比Armijo准则更严格的步长选择策略，它包含两个条件：

1. **充分下降条件**（与Armijo准则相同）：$f(x_k - \alpha \nabla f(x_k)) \leq f(x_k) - \sigma \alpha \lVert \nabla f(x_k) \rVert^2$。
2. **曲率条件**：$\nabla f(x_k - \alpha \nabla f(x_k))^T \nabla f(x_k) \geq \rho \lVert \nabla f(x_k) \rVert^2$，其中 $\rho \in (\sigma, 1)$。

曲率条件保证了步长不会太小，从而提高了算法的收敛速度。

### 4.1.3 动量法

动量法是对梯度下降法的改进，它在更新迭代点时不仅考虑当前的梯度，还考虑之前的梯度方向，从而加速算法的收敛。

#### 算法步骤

1. 选择初始点 $x_0 \in \mathbb{R}^n$，初始速度 $v_0 = 0$，设置迭代次数 $k=0$。
2. 计算梯度 $g_k = \nabla f(x_k)$。
3. 如果 $\lVert g_k \rVert \leq \epsilon$，则停止迭代，输出 $x_k$。
4. 更新速度：$v_{k+1} = \gamma v_k + \alpha_k g_k$，其中 $\gamma \in [0, 1)$ 是动量系数。
5. 更新迭代点：$x_{k+1} = x_k - v_{k+1}$。
6. 令 $k = k + 1$，返回步骤 2。

#### 动量法的数学表达式

动量法的更新规则可以表示为：

$$v_{k+1} = \gamma v_k + \alpha_k \nabla f(x_k)$$

$$x_{k+1} = x_k - v_{k+1}$$

其中 $\gamma$ 是动量系数，控制之前梯度方向的影响程度；$\alpha_k$ 是步长。

#### 动量法的几何解释

动量法可以理解为在梯度下降的基础上增加了一个"惯性"项，使得算法在下降方向上的移动更加平滑，同时能够更快地通过平坦区域和小曲率区域。

### 4.1.4 随机梯度下降

随机梯度下降（Stochastic Gradient Descent，SGD）是梯度下降法的一种变体，主要用于处理大规模机器学习问题，特别是在训练神经网络时。

#### 算法步骤

在机器学习中，目标函数通常是损失函数在训练数据集上的平均值：

$$f(x) = \frac{1}{m} \sum_{i=1}^m f_i(x)$$

其中 $f_i(x)$ 是第 $i$ 个样本的损失函数，$m$ 是样本数量。

随机梯度下降的算法步骤如下：

1. 选择初始点 $x_0 \in \mathbb{R}^n$，设置迭代次数 $k=0$。
2. 从训练数据集中随机选择一个样本 $i_k$。
3. 计算随机梯度：$g_k = \nabla f_{i_k}(x_k)$。
4. 更新迭代点：$x_{k+1} = x_k - \alpha_k g_k$，其中 $\alpha_k$ 是步长。
5. 令 $k = k + 1$，返回步骤 2，直到满足收敛条件。

#### 随机梯度下降的优缺点

**优点：**
- 每次迭代的计算量小，仅需计算单个样本的梯度。
- 适用于在线学习和大规模数据集。
- 能够逃离局部最优解。

**缺点：**
- 收敛过程可能不稳定，存在波动。
- 步长的选择更加困难。
- 收敛速度可能较慢。

## 4.2 二阶方法

二阶方法是使用目标函数的二阶导数（海森矩阵）信息来求解优化问题的算法。这类方法收敛速度快，但计算复杂度较高。

### 4.2.1 牛顿法

牛顿法是一种经典的二阶优化算法，其基本思想是在每一步迭代中，用目标函数的二次泰勒展开来近似目标函数，然后求解这个二次函数的最小值，作为下一次迭代的点。

#### 算法步骤

1. 选择初始点 $x_0 \in \mathbb{R}^n$，设置迭代次数 $k=0$。
2. 计算梯度 $g_k = \nabla f(x_k)$。
3. 如果 $\lVert g_k \rVert \leq \epsilon$，则停止迭代，输出 $x_k$。
4. 计算海森矩阵 $H_k = \nabla^2 f(x_k)$。
5. 求解线性方程组：$H_k d_k = -g_k$，得到搜索方向 $d_k$。
6. 更新迭代点：$x_{k+1} = x_k + d_k$。
7. 令 $k = k + 1$，返回步骤 2。

#### 牛顿法的数学推导

对于二次可微的函数 $f(x)$，在点 $x_k$ 处的二阶泰勒展开为：

$$f(x) \approx f(x_k) + \nabla f(x_k)^T (x - x_k) + \frac{1}{2} (x - x_k)^T \nabla^2 f(x_k) (x - x_k)$$

为了找到这个二次近似函数的最小值，我们对其求导并令导数为零：

$$\nabla f(x_k) + \nabla^2 f(x_k) (x - x_k) = 0$$

解得：

$$x = x_k - [\nabla^2 f(x_k)]^{-1} \nabla f(x_k)$$

这就是牛顿法的更新规则，其中搜索方向 $d_k = -[\nabla^2 f(x_k)]^{-1} \nabla f(x_k)$ 称为牛顿方向。

#### 牛顿法的优缺点

**优点：**
- 收敛速度快，在最优解附近具有二次收敛性。
- 能够处理目标函数的曲率信息。

**缺点：**
- 每次迭代需要计算海森矩阵并求解线性方程组，计算复杂度高。
- 海森矩阵可能是奇异的或非正定的，导致算法不稳定。
- 仅适用于小规模优化问题。

### 4.2.2 拟牛顿法

拟牛顿法是对牛顿法的改进，它通过构造一个近似海森矩阵（或其逆矩阵）来避免计算真实的海森矩阵，从而减少计算复杂度。

#### BFGS算法

BFGS算法是最常用的拟牛顿法之一，由Broyden、Fletcher、Goldfarb和Shanno四人提出。它通过迭代更新近似海森矩阵的逆矩阵 $B_k$。

#### BFGS算法步骤

1. 选择初始点 $x_0 \in \mathbb{R}^n$，初始近似海森矩阵的逆矩阵 $B_0 = I$（单位矩阵），设置迭代次数 $k=0$。
2. 计算梯度 $g_k = \nabla f(x_k)$。
3. 如果 $\lVert g_k \rVert \leq \epsilon$，则停止迭代，输出 $x_k$。
4. 计算搜索方向：$d_k = -B_k g_k$。
5. 使用线搜索确定步长 $\alpha_k$。
6. 更新迭代点：$x_{k+1} = x_k + \alpha_k d_k$。
7. 计算新的梯度：$g_{k+1} = \nabla f(x_{k+1})$。
8. 计算差值：$s_k = x_{k+1} - x_k = \alpha_k d_k$，$y_k = g_{k+1} - g_k$。
9. 更新近似海森矩阵的逆矩阵：

   $$B_{k+1} = B_k + \frac{s_k s_k^T}{s_k^T y_k} - \frac{B_k y_k y_k^T B_k}{y_k^T B_k y_k}$$

10. 令 $k = k + 1$，返回步骤 2。

#### DFP算法

DFP算法是另一种常用的拟牛顿法，由Davidon、Fletcher和Powell三人提出。它通过迭代更新近似海森矩阵 $H_k$。

DFP算法的更新规则为：

$$H_{k+1} = H_k + \frac{y_k y_k^T}{y_k^T s_k} - \frac{H_k s_k s_k^T H_k}{s_k^T H_k s_k}$$

其中 $s_k = x_{k+1} - x_k$，$y_k = g_{k+1} - g_k$。

#### 拟牛顿法的优缺点

**优点：**
- 不需要计算真实的海森矩阵，减少了计算复杂度。
- 收敛速度比一阶方法快。
- 适用于中等规模的优化问题。

**缺点：**
- 每次迭代需要存储近似海森矩阵（或其逆矩阵），空间复杂度为 $O(n^2)$。
- 对于大规模优化问题，仍然不够高效。

### 4.2.3 共轭梯度法

共轭梯度法是一种特殊的一阶方法，它通过构造一组共轭方向来加速收敛，同时避免了存储大型矩阵的需求。

#### 共轭方向的定义

对于对称正定矩阵 $A$，如果两个向量 $d_i$ 和 $d_j$ 满足：

$$d_i^T A d_j = 0$$

则称 $d_i$ 和 $d_j$ 关于 $A$ 共轭。

#### 共轭梯度法的基本思想

共轭梯度法的基本思想是：对于二次函数 $f(x) = \frac{1}{2} x^T A x + b^T x + c$（其中 $A$ 是对称正定矩阵），通过构造一组关于 $A$ 共轭的搜索方向，使得算法能够在 $n$ 次迭代内（$n$ 是变量维度）找到最优解。

#### 共轭梯度法步骤

对于一般的无约束优化问题，共轭梯度法的步骤如下：

1. 选择初始点 $x_0 \in \mathbb{R}^n$，计算梯度 $g_0 = \nabla f(x_0)$。
2. 设置初始搜索方向：$d_0 = -g_0$。
3. 对于 $k=0,1,2,\ldots$：
   a. 使用线搜索确定步长 $\alpha_k$，使得 $f(x_k + \alpha_k d_k)$ 最小。
   b. 更新迭代点：$x_{k+1} = x_k + \alpha_k d_k$。
   c. 计算新的梯度：$g_{k+1} = \nabla f(x_{k+1})$。
   d. 如果 $\lVert g_{k+1} \rVert \leq \epsilon$，则停止迭代，输出 $x_{k+1}$。
   e. 计算共轭系数：$\beta_k = \frac{g_{k+1}^T g_{k+1}}{g_k^T g_k}$（Fletcher-Reeves公式）。
   f. 更新搜索方向：$d_{k+1} = -g_{k+1} + \beta_k d_k$。

#### 共轭梯度法的优缺点

**优点：**
- 不需要存储大型矩阵，空间复杂度为 $O(n)$。
- 对于二次函数，能够在 $n$ 次迭代内找到最优解。
- 适用于大规模优化问题。

**缺点：**
- 对于非二次函数，收敛速度可能较慢。
- 线搜索的质量对算法性能影响较大。

## 4.3 算法收敛性分析

### 4.3.1 收敛速率的定义

收敛速率是衡量优化算法收敛快慢的重要指标。常见的收敛速率定义如下：

#### 线性收敛

如果存在常数 $0 < q < 1$ 和 $k_0 \geq 0$，使得对于所有 $k \geq k_0$，有：

$$\lVert x_{k+1} - x^* \rVert \leq q \lVert x_k - x^* \rVert$$

则称算法线性收敛，收敛速率为 $q$。

#### 超线性收敛

如果：

$$\lim_{k \to \infty} \frac{\lVert x_{k+1} - x^* \rVert}{\lVert x_k - x^* \rVert} = 0$$

则称算法超线性收敛。

#### 二次收敛

如果存在常数 $M > 0$ 和 $k_0 \geq 0$，使得对于所有 $k \geq k_0$，有：

$$\lVert x_{k+1} - x^* \rVert \leq M \lVert x_k - x^* \rVert^2$$

则称算法二次收敛。

### 4.3.2 一阶方法的收敛性

#### 梯度下降法的收敛性

对于梯度 Lipschitz 连续的函数（即存在常数 $L > 0$，使得 $\lVert \nabla f(x) - \nabla f(y) \rVert \leq L \lVert x - y \rVert$ 对所有 $x, y$ 成立），使用固定步长 $\alpha \leq 1/L$ 的梯度下降法是线性收敛的。

#### 随机梯度下降的收敛性

对于凸函数，随机梯度下降在期望意义下是线性收敛的。对于非凸函数，随机梯度下降能够收敛到一个 stationary point（即梯度为零的点）。

### 4.3.3 二阶方法的收敛性

#### 牛顿法的收敛性

对于二次连续可微的函数，如果初始点足够接近最优解 $x^*$，且海森矩阵 $\nabla^2 f(x^*)$ 是正定的，则牛顿法是二次收敛的。

#### 拟牛顿法的收敛性

拟牛顿法（如BFGS）在适当的条件下是超线性收敛的。对于二次函数，BFGS算法能够在 $n$ 次迭代内找到最优解。

#### 共轭梯度法的收敛性

对于二次函数，共轭梯度法能够在 $n$ 次迭代内找到最优解。对于非二次函数，共轭梯度法的收敛速度取决于目标函数与二次函数的接近程度。

## 4.4 小结

本章介绍了无约束优化的主要算法，包括：

1. **一阶方法**：
   - 梯度下降法：基本的一阶优化算法，沿着梯度负方向移动。
   - 步长选择策略：固定步长、Armijo准则、Wolfe条件。
   - 动量法：通过考虑之前的梯度方向来加速收敛。
   - 随机梯度下降：适用于大规模机器学习问题。

2. **二阶方法**：
   - 牛顿法：使用海森矩阵信息，收敛速度快。
   - 拟牛顿法：通过构造近似海森矩阵来减少计算复杂度。
   - 共轭梯度法：通过构造共轭方向来加速收敛，适用于大规模问题。

3. **算法收敛性分析**：
   - 收敛速率的定义：线性收敛、超线性收敛、二次收敛。
   - 各种算法的收敛性分析。

在实际应用中，选择哪种优化算法取决于具体问题的特点，如问题规模、目标函数的性质、计算资源等。对于大规模问题，通常选择一阶方法（如随机梯度下降）；对于中小规模问题，二阶方法（如BFGS）可能会更有效。

在下一章中，我们将学习约束优化算法，即如何求解带有约束条件的优化问题。

## 习题

### 基础题

**习题4.1**：使用梯度下降法求解函数 $f(x) = x_1^2 + 2x_2^2$ 的最小值，初始点为 $x_0 = (2, 1)^T$，步长为 $\alpha = 0.1$，迭代5次。

**习题4.2**：计算函数 $f(x) = x_1^3 + x_2^3 - 3x_1 - 3x_2$ 的梯度和海森矩阵。

**习题4.3**：简述梯度下降法的基本思想和步骤。

### 中等题

**习题4.4**：使用牛顿法求解函数 $f(x) = x_1^2 + 2x_2^2$ 的最小值，初始点为 $x_0 = (2, 1)^T$，迭代3次。

**习题4.5**：证明对于正定二次函数，牛顿法一步即可收敛到最优解。

**习题4.6**：比较梯度下降法和牛顿法的优缺点。

**习题4.7**：使用梯度下降法求解函数 $f(x) = (x_1 - 1)^2 + (x_2 - 2)^2$ 的最小值，初始点为 $x_0 = (0, 0)^T$，步长为 $\alpha = 0.1$，迭代10次，并计算最终点的函数值。

习题解答[点击这里](docs/quiz/exercise_solutions.md)

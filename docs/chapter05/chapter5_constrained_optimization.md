# 第5章 约束优化算法

## 5.1 等式约束优化

在实际应用中，许多优化问题都带有约束条件。本节首先介绍等式约束优化问题的求解方法。

### 5.1.1 拉格朗日乘数法

在高等数学的多元微积分部分，就有介绍过拉格朗日乘数法了。不过当时也仅作为解决最值问题的一大利器，并未对其进行更深入的研究。接下来，我们仔细拆解其中奥妙，并挖掘它不曾被发现的性质。

拉格朗日乘数法是求解等式约束优化问题的经典方法，它通过引入拉格朗日乘数将约束优化问题转化为无约束优化问题。

#### 问题形式

考虑等式约束优化问题：

$$\min_{x} f(x)$$

$$\text{s.t. } h_j(x) = 0, \quad j=1,2,\ldots,p$$

其中 $f: \mathbb{R}^n \to \mathbb{R}$ 是目标函数，$h_j: \mathbb{R}^n \to \mathbb{R}$ 是等式约束函数。

#### 拉格朗日函数

引入拉格朗日乘数 $\lambda_j \in \mathbb{R}, j=1,2,\ldots,p$，构造拉格朗日函数：

$$L(x, \lambda) = f(x) - \sum_{j=1}^p \lambda_j h_j(x)$$

#### 最优性条件

如果 $x^*$ 是原问题的最优解，且满足一定的正则条件（如约束梯度线性无关），则存在拉格朗日乘数 $\lambda^*$，使得：

$$\nabla_x L(x^*, \lambda^*) = \nabla f(x^*) - \sum_{j=1}^p \lambda_j^* \nabla h_j(x^*) = 0$$

$$\nabla_\lambda L(x^*, \lambda^*) = -h(x^*) = 0$$

这些条件称为**一阶最优性条件**或**Kuhn-Tucker条件**（对于等式约束问题，也称为**拉格朗日条件**）。

#### 拉格朗日乘数法的几何解释

拉格朗日条件的几何意义是：在最优解处，目标函数的梯度是约束函数梯度的线性组合。换句话说，目标函数在最优解处的负梯度方向位于约束曲面的切平面内。

#### 示例：二维等式约束问题

考虑问题：

$$\min_{x_1, x_2} x_1^2 + x_2^2$$

$$\text{s.t. } x_1 + x_2 = 1$$

构造拉格朗日函数：

$$L(x_1, x_2, \lambda) = x_1^2 + x_2^2 - \lambda (x_1 + x_2 - 1)$$

求偏导并令其为零：

$$\frac{\partial L}{\partial x_1} = 2x_1 - \lambda = 0$$

$$\frac{\partial L}{\partial x_2} = 2x_2 - \lambda = 0$$

$$\frac{\partial L}{\partial \lambda} = -(x_1 + x_2 - 1) = 0$$

解得：$x_1^* = x_2^* = 1/2$，$\lambda^* = 1$。

### 5.1.2 梯度投影法

梯度投影法是一种求解等式约束优化问题的迭代算法，它通过将梯度投影到约束曲面的切平面上，然后沿着投影后的负梯度方向搜索。

#### 问题形式

考虑线性等式约束优化问题：

$$\min_{x} f(x)$$

$$\text{s.t. } Ax = b$$

其中 $A \in \mathbb{R}^{p \times n}$ 是行满秩的约束矩阵，$b \in \mathbb{R}^p$ 是约束右侧向量。

#### 投影矩阵

约束 $Ax = b$ 的可行域是一个仿射子空间，其切空间是 $\{d \in \mathbb{R}^n \mid Ad = 0\}$。切空间的正交补空间是 $\{A^T y \mid y \in \mathbb{R}^p\}$。

投影矩阵 $P$ 定义为将任意向量投影到切空间上的线性变换，即：

$$P = I - A^T (AA^T)^{-1} A$$

其中 $I$ 是单位矩阵。

#### 算法步骤

梯度投影法的算法步骤如下：

1. 选择初始可行点 $x_0$（满足 $Ax_0 = b$），设置迭代次数 $k=0$。
2. 计算梯度 $g_k = \nabla f(x_k)$。
3. 计算投影梯度：$P g_k$。
4. 如果 $\lVert P g_k \rVert \leq \epsilon$，则停止迭代，输出 $x_k$。
5. 沿着投影负梯度方向搜索：$d_k = -P g_k$。
6. 使用线搜索确定步长 $\alpha_k$，使得 $f(x_k + \alpha_k d_k)$ 最小，同时保持可行性（由于 $d_k$ 位于切空间，所以对于任意 $\alpha_k$，$x_k + \alpha_k d_k$ 都是可行的）。
7. 更新迭代点：$x_{k+1} = x_k + \alpha_k d_k$。
8. 令 $k = k + 1$，返回步骤 2。

#### 梯度投影法的优缺点

**优点：**
- 每次迭代都保持可行性，适用于对可行性要求严格的问题。
- 算法简单，易于实现。

**缺点：**
- 仅适用于线性等式约束问题。
- 收敛速度可能较慢。

## 5.2 不等式约束优化

不等式约束优化问题比等式约束优化问题更加复杂，因为需要处理不等式约束的激活与非激活状态。

### 5.2.1 KKT条件

KKT条件（Karush-Kuhn-Tucker条件）是不等式约束优化问题的一阶最优性条件，它是拉格朗日条件对不等式约束的扩展。

#### 问题形式

考虑不等式约束优化问题：

$$\min_{x} f(x)$$

$$\text{s.t. } g_i(x) \leq 0, \quad i=1,2,\ldots,m$$

$$h_j(x) = 0, \quad j=1,2,\ldots,p$$

其中 $f: \mathbb{R}^n \to \mathbb{R}$ 是目标函数，$g_i: \mathbb{R}^n \to \mathbb{R}$ 是不等式约束函数，$h_j: \mathbb{R}^n \to \mathbb{R}$ 是等式约束函数。

#### 拉格朗日函数

引入拉格朗日乘数 $\mu_i \in \mathbb{R}, i=1,2,\ldots,m$（对应不等式约束）和 $\lambda_j \in \mathbb{R}, j=1,2,\ldots,p$（对应等式约束），构造拉格朗日函数：

$$L(x, \mu, \lambda) = f(x) - \sum_{i=1}^m \mu_i g_i(x) - \sum_{j=1}^p \lambda_j h_j(x)$$

#### KKT条件

如果 $x^*$ 是原问题的最优解，且满足一定的正则条件（如约束资格），则存在拉格朗日乘数 $\mu^* \geq 0$ 和 $\lambda^*$，使得：

1. **梯度条件**：$\nabla_x L(x^*, \mu^*, \lambda^*) = \nabla f(x^*) - \sum_{i=1}^m \mu_i^* \nabla g_i(x^*) - \sum_{j=1}^p \lambda_j^* \nabla h_j(x^*) = 0$。
2. **原始可行性条件**：$g_i(x^*) \leq 0, i=1,2,\ldots,m$；$h_j(x^*) = 0, j=1,2,\ldots,p$。
3. **对偶可行性条件**：$\mu_i^* \geq 0, i=1,2,\ldots,m$。
4. **互补松弛条件**：$\mu_i^* g_i(x^*) = 0, i=1,2,\ldots,m$。

互补松弛条件的意义是：对于不等式约束 $g_i(x) \leq 0$，如果在最优解处约束是严格满足的（即 $g_i(x^*) < 0$），则对应的拉格朗日乘数 $\mu_i^* = 0$；如果对应的拉格朗日乘数 $\mu_i^* > 0$，则在最优解处约束是紧的（即 $g_i(x^*) = 0$）。

#### 示例：二维不等式约束问题

考虑问题：

$$\min_{x_1, x_2} x_1^2 + x_2^2$$

$$\text{s.t. } x_1 + x_2 \geq 1$$

构造拉格朗日函数：

$$L(x_1, x_2, \mu) = x_1^2 + x_2^2 - \mu (x_1 + x_2 - 1)$$

其中 $\mu \geq 0$。

KKT条件为：

$$\frac{\partial L}{\partial x_1} = 2x_1 - \mu = 0$$

$$\frac{\partial L}{\partial x_2} = 2x_2 - \mu = 0$$

$$\frac{\partial L}{\partial \mu} = -(x_1 + x_2 - 1) = 0$$

$$\mu \geq 0$$

$$\mu (x_1 + x_2 - 1) = 0$$

解得：$x_1^* = x_2^* = 1/2$，$\mu^* = 1$。

### 5.2.2 可行方向法

可行方向法是一类求解不等式约束优化问题的迭代算法，它通过在每一步迭代中寻找一个可行下降方向，然后沿着该方向搜索。

#### 可行方向的定义

对于可行点 $x$，如果存在 $\alpha_0 > 0$，使得对于所有 $\alpha \in [0, \alpha_0]$，都有 $x + \alpha d$ 是可行的，则称方向 $d$ 是 $x$ 处的可行方向。

#### 下降方向的定义

对于点 $x$，如果存在 $\alpha_0 > 0$，使得对于所有 $\alpha \in (0, \alpha_0]$，都有 $f(x + \alpha d) < f(x)$，则称方向 $d$ 是 $x$ 处的下降方向。

#### 可行下降方向的条件

方向 $d$ 是可行下降方向的条件是：

1. **可行方向条件**：对于所有 $i$ 满足 $g_i(x) = 0$（即紧约束），有 $\nabla g_i(x)^T d \leq 0$。
2. **下降方向条件**：$\nabla f(x)^T d < 0$。

#### Zoutendijk可行方向法

Zoutendijk可行方向法是一种经典的可行方向法，其步骤如下：

1. 选择初始可行点 $x_0$，设置迭代次数 $k=0$。
2. 确定当前点的紧约束集合：$I(x_k) = \{i \mid g_i(x_k) = 0\}$。
3. 求解线性规划问题，寻找可行下降方向：

   $$\min_{d} \nabla f(x_k)^T d$$

   $$\text{s.t. } \nabla g_i(x_k)^T d \leq 0, \quad i \in I(x_k)$$

   $$\lVert d \rVert \leq 1$$

4. 如果最优值 $\geq -\epsilon$，则停止迭代，输出 $x_k$。
5. 使用线搜索确定步长 $\alpha_k$，使得 $f(x_k + \alpha_k d_k)$ 最小，同时保持可行性。
6. 更新迭代点：$x_{k+1} = x_k + \alpha_k d_k$。
7. 令 $k = k + 1$，返回步骤 2。

### 5.2.3 梯度投影法的扩展

梯度投影法可以扩展到处理不等式约束问题，称为**投影梯度法**或**条件梯度法**。

#### 问题形式

考虑线性不等式约束优化问题：

$$\min_{x} f(x)$$

$$\text{s.t. } Ax \leq b$$

其中 $A \in \mathbb{R}^{m \times n}$ 是约束矩阵，$b \in \mathbb{R}^m$ 是约束右侧向量。

#### 投影算子

对于闭凸集 $C$，投影算子 $P_C: \mathbb{R}^n \to C$ 定义为：

$$P_C(x) = \arg\min_{y \in C} \lVert y - x \rVert^2$$

即 $P_C(x)$ 是 $C$ 中与 $x$ 距离最近的点。

#### 算法步骤

投影梯度法的算法步骤如下：

1. 选择初始可行点 $x_0 \in C$，设置迭代次数 $k=0$。
2. 计算梯度 $g_k = \nabla f(x_k)$。
3. 计算搜索方向：$d_k = P_C(x_k - \alpha_k g_k) - x_k$，其中 $\alpha_k$ 是步长。
4. 如果 $\lVert d_k \rVert \leq \epsilon$，则停止迭代，输出 $x_k$。
5. 更新迭代点：$x_{k+1} = x_k + d_k$。
6. 令 $k = k + 1$，返回步骤 2。

#### 投影梯度法的几何解释

投影梯度法的基本思想是：首先沿着负梯度方向迈出一步，然后将结果投影回可行域，以保持可行性。

## 5.3 内点法

内点法是一类求解凸优化问题的有效算法，它通过在目标函数中添加障碍函数来处理不等式约束，从而将约束优化问题转化为一系列无约束优化问题。

### 5.3.1 障碍函数法

障碍函数法是内点法的一种，它通过在目标函数中添加对数障碍函数来惩罚不可行点。

#### 问题形式

考虑凸优化问题：

$$\min_{x} f(x)$$

$$\text{s.t. } g_i(x) \leq 0, \quad i=1,2,\ldots,m$$

其中 $f$ 和 $g_i$ 都是凸函数。

#### 对数障碍函数

对数障碍函数定义为：

$$\phi(x) = -\sum_{i=1}^m \log(-g_i(x))$$

障碍函数在可行域的内部有定义，当 $x$ 接近可行域的边界时，$\phi(x)$ 趋向于正无穷大。

#### 障碍问题

对于给定的参数 $t > 0$，障碍问题定义为：

$$\min_{x} f(x) + \frac{1}{t} \phi(x)$$

当 $t$ 增大时，障碍问题的解趋近于原问题的解。

#### 算法步骤

障碍函数法的算法步骤如下：

1. 选择初始内点 $x_0$（满足 $g_i(x_0) < 0, i=1,2,\ldots,m$），初始参数 $t_0 > 0$，放大因子 $\mu > 1$，设置迭代次数 $k=0$。
2. 求解障碍问题：$x_k = \arg\min_{x} f(x) + \frac{1}{t_k} \phi(x)$。
3. 如果 $m/t_k \leq \epsilon$，则停止迭代，输出 $x_k$。
4. 更新参数：$t_{k+1} = \mu t_k$。
5. 令 $k = k + 1$，返回步骤 2。

### 5.3.2 原始对偶内点法

原始对偶内点法是一种更高效的内点法，它同时处理原始变量和对偶变量，具有更好的数值稳定性和收敛性。

#### 原始对偶内点法的基本思想

原始对偶内点法的基本思想是：通过构造原始变量和对偶变量的搜索方向，使得原始可行性、对偶可行性和互补松弛条件同时得到满足。

#### 算法步骤

原始对偶内点法的算法步骤如下：

1. 选择初始原始变量 $x_0$（满足 $g_i(x_0) < 0, i=1,2,\ldots,m$），初始对偶变量 $\mu_0 > 0$，$\lambda_0$，设置迭代次数 $k=0$。
2. 计算互补松弛间隙：$\tau = \frac{\mu^T g(x)}{m}$，其中 $g(x) = (g_1(x), \ldots, g_m(x))^T$。
3. 如果 $\tau \leq \epsilon$，则停止迭代，输出 $x_k$。
4. 计算搜索方向 $(\Delta x, \Delta \mu, \Delta \lambda)$，满足：

   $$\nabla f(x) - \sum_{i=1}^m \mu_i \nabla g_i(x) - \sum_{j=1}^p \lambda_j \nabla h_j(x) + \nabla^2_{xx} L \Delta x - \sum_{i=1}^m \Delta \mu_i \nabla g_i(x) - \sum_{j=1}^p \Delta \lambda_j \nabla h_j(x) = 0$$

   $$-g_i(x) \Delta \mu_i + \mu_i \Delta g_i(x) = -\sigma \tau e_i, \quad i=1,2,\ldots,m$$

   $$h_j(x) + \nabla h_j(x)^T \Delta x = 0, \quad j=1,2,\ldots,p$$

   其中 $\sigma \in (0, 1)$ 是中心参数，$e_i$ 是单位向量。

5. 确定步长 $\alpha$，使得 $x + \alpha \Delta x$ 保持可行，$\mu + \alpha \Delta \mu > 0$。
6. 更新变量：$x_{k+1} = x_k + \alpha \Delta x$，$\mu_{k+1} = \mu_k + \alpha \Delta \mu$，$\lambda_{k+1} = \lambda_k + \alpha \Delta \lambda$。
7. 令 $k = k + 1$，返回步骤 2。

### 5.3.3 内点法的计算复杂度

内点法的计算复杂度是衡量其效率的重要指标。对于标准形式的线性规划问题，内点法的计算复杂度为 $O(n^3 L)$，其中 $n$ 是变量维度，$L$ 是问题的输入长度。

对于一般的凸优化问题，内点法的计算复杂度取决于问题的规模和条件数，但通常比单纯形法等传统方法更适合处理大规模问题。

## 5.4 罚函数与增广拉格朗日法

罚函数法和增广拉格朗日法是另一类求解约束优化问题的方法，它们通过在目标函数中添加罚项来处理约束。

### 5.4.1 罚函数法

罚函数法通过在目标函数中添加罚项来惩罚违反约束的行为，从而将约束优化问题转化为无约束优化问题。

#### 外部罚函数法

外部罚函数法定义罚函数为：

$$F(x, c) = f(x) + c \sum_{i=1}^m \max(g_i(x), 0) + c \sum_{j=1}^p |h_j(x)|$$

其中 $c > 0$ 是罚参数。当 $c$ 增大时，罚函数的最小值趋近于原问题的最优值。

#### 内部罚函数法

内部罚函数法（也称为障碍函数法）定义罚函数为：

$$F(x, c) = f(x) - \frac{1}{c} \sum_{i=1}^m \log(-g_i(x))$$

其中 $c > 0$ 是罚参数。内部罚函数法要求初始点是可行的，并且只能处理不等式约束。

#### 罚函数法的优缺点

**优点：**
- 算法简单，易于实现。
- 可以使用无约束优化算法求解。

**缺点：**
- 罚参数的选择困难，太小会导致约束违反，太大会导致病态问题。
- 收敛速度慢，特别是对于接近最优解的情况。

### 5.4.2 增广拉格朗日法

增广拉格朗日法（也称为惩罚拉格朗日法）是对拉格朗日乘数法和罚函数法的结合，它通过在拉格朗日函数中添加二次罚项来提高算法的稳定性和收敛性。

#### 增广拉格朗日函数

对于等式约束优化问题：

$$\min_{x} f(x)$$

$$\text{s.t. } h_j(x) = 0, \quad j=1,2,\ldots,p$$

增广拉格朗日函数定义为：

$$L_c(x, \lambda) = f(x) - \sum_{j=1}^p \lambda_j h_j(x) + \frac{c}{2} \sum_{j=1}^p h_j(x)^2$$

其中 $c > 0$ 是罚参数，$\lambda_j$ 是拉格朗日乘数。

对于不等式约束优化问题，可以通过引入松弛变量将其转化为等式约束问题，然后应用增广拉格朗日法。

#### 算法步骤

增广拉格朗日法的算法步骤如下：

1. 选择初始点 $x_0$，初始拉格朗日乘数 $\lambda_0$，初始罚参数 $c_0 > 0$，放大因子 $\rho > 1$，设置迭代次数 $k=0$。
2. 固定 $\lambda_k$ 和 $c_k$，求解无约束优化问题：$x_{k+1} = \arg\min_{x} L_{c_k}(x, \lambda_k)$。
3. 更新拉格朗日乘数：$\lambda_{k+1} = \lambda_k - c_k h(x_{k+1})$。
4. 检查收敛条件：如果 $\lVert h(x_{k+1}) \rVert \leq \epsilon$，则停止迭代，输出 $x_{k+1}$。
5. 否则，更新罚参数：$c_{k+1} = \rho c_k$。
6. 令 $k = k + 1$，返回步骤 2。

### 5.4.3 交替方向乘子法(ADMM)

交替方向乘子法（Alternating Direction Method of Multipliers，ADMM）是增广拉格朗日法的一种变体，特别适用于处理可分离的大规模优化问题。

#### 问题形式

考虑可分离的凸优化问题：

$$\min_{x, z} f(x) + g(z)$$

$$\text{s.t. } Ax + Bz = c$$

其中 $f$ 和 $g$ 是凸函数，$A$、$B$ 是矩阵，$c$ 是向量。

#### 增广拉格朗日函数

增广拉格朗日函数定义为：

$$L_\rho(x, z, \lambda) = f(x) + g(z) - \lambda^T (Ax + Bz - c) + \frac{\rho}{2} \lVert Ax + Bz - c \rVert^2$$

其中 $\rho > 0$ 是罚参数，$\lambda$ 是拉格朗日乘数。

#### 算法步骤

ADMM的算法步骤如下：

1. 选择初始点 $x_0$，$z_0$，初始拉格朗日乘数 $\lambda_0$，罚参数 $\rho > 0$，设置迭代次数 $k=0$。
2. **x-更新**：固定 $z_k$ 和 $\lambda_k$，求解：$x_{k+1} = \arg\min_{x} L_\rho(x, z_k, \lambda_k)$。
3. **z-更新**：固定 $x_{k+1}$ 和 $\lambda_k$，求解：$z_{k+1} = \arg\min_{z} L_\rho(x_{k+1}, z, \lambda_k)$。
4. **λ-更新**：$\lambda_{k+1} = \lambda_k - \rho (Ax_{k+1} + Bz_{k+1} - c)$。
5. 检查收敛条件：如果 $\lVert Ax_{k+1} + Bz_{k+1} - c \rVert \leq \epsilon$ 且 $\lVert x_{k+1} - x_k \rVert \leq \epsilon$ 且 $\lVert z_{k+1} - z_k \rVert \leq \epsilon$，则停止迭代，输出 $x_{k+1}$ 和 $z_{k+1}$。
6. 令 $k = k + 1$，返回步骤 2。

#### ADMM的优缺点

**优点：**
- 可以处理大规模优化问题，特别是当目标函数可分离时。
- 具有良好的并行性，适合分布式计算。
- 收敛性有理论保证。

**缺点：**
- 罚参数的选择会影响收敛速度。
- 对于某些问题，收敛可能较慢。

## 5.5 小结

本章介绍了约束优化的主要算法，包括：

1. **等式约束优化**：
   - 拉格朗日乘数法：通过引入拉格朗日乘数将约束优化问题转化为无约束优化问题。
   - 梯度投影法：将梯度投影到约束曲面的切平面上，然后沿着投影后的负梯度方向搜索。

2. **不等式约束优化**：
   - KKT条件：不等式约束优化问题的一阶最优性条件。
   - 可行方向法：通过寻找可行下降方向来迭代求解。
   - 投影梯度法：通过投影操作保持可行性。

3. **内点法**：
   - 障碍函数法：通过添加对数障碍函数来处理不等式约束。
   - 原始对偶内点法：同时处理原始变量和对偶变量，具有更好的收敛性。

4. **罚函数与增广拉格朗日法**：
   - 罚函数法：通过添加罚项来惩罚违反约束的行为。
   - 增广拉格朗日法：结合拉格朗日乘数法和罚函数法的优点。
   - 交替方向乘子法(ADMM)：特别适用于处理可分离的大规模优化问题。

在实际应用中，选择哪种约束优化算法取决于具体问题的特点，如问题规模、约束类型、目标函数的性质等。对于大规模凸优化问题，内点法和ADMM通常是较好的选择；对于小规模问题，可行方向法和增广拉格朗日法可能更有效。

在下一章中，我们将学习对偶理论，它是凸优化的重要组成部分，对于理解和求解凸优化问题具有重要意义。

## 习题

### 基础题

**习题5.1**：使用拉格朗日乘数法求解下列问题：

$$\min_{x} x_1^2 + x_2^2$$

$$\text{s.t. } x_1 + x_2 = 1$$

**习题5.2**：写出下列问题的拉格朗日函数：

$$\min_{x} x_1^2 + 2x_2^2$$

$$\text{s.t. } x_1 + x_2 \geq 1$$

$$x_1, x_2 \geq 0$$

**习题5.3**：简述拉格朗日乘数法的基本思想。

### 中等题

**习题5.4**：使用拉格朗日乘数法求解下列问题：

$$\min_{x} x_1^2 + x_2^2 + x_3^2$$

$$\text{s.t. } x_1 + x_2 + x_3 = 3$$

$$x_1 - x_2 = 1$$

**习题5.5**：证明对于凸优化问题，满足KKT条件的点是全局最优解。

**习题5.6**：使用拉格朗日乘数法求解下列问题：

$$\max_{x} x_1 x_2$$

$$\text{s.t. } x_1 + x_2 = 2$$

$$x_1, x_2 \geq 0$$

习题解答[点击这里](quiz/exercise_solutions.md)

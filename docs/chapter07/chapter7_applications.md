# 第7章 应用案例

凸优化在各个领域都有广泛的应用，本章将介绍凸优化在机器学习、信号处理、控制系统和金融等领域的典型应用案例。

## 7.1 机器学习中的应用

机器学习中的许多问题都可以建模为凸优化问题，特别是在监督学习中，正则化方法的引入使得优化问题保持凸性。

### 7.1.1 线性回归与岭回归

#### 线性回归

线性回归是最基本的监督学习算法之一，它的目标是拟合一个线性模型来预测连续值输出。

**问题形式**：给定训练数据 $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$，其中 $x_i \in \mathbb{R}^d$ 是输入特征，$y_i \in \mathbb{R}$ 是输出标签，我们希望找到参数 $w \in \mathbb{R}^d$ 和 $b \in \mathbb{R}$，使得线性模型 $y = w^T x + b$ 能够最好地拟合训练数据。

**损失函数**：线性回归通常使用均方误差（MSE）作为损失函数：

$$L(w, b) = \frac{1}{n} \sum_{i=1}^n (w^T x_i + b - y_i)^2$$

**优化问题**：线性回归的优化问题可以表示为：

$$\min_{w, b} \frac{1}{n} \sum_{i=1}^n (w^T x_i + b - y_i)^2$$

这是一个无约束凸优化问题，因为目标函数是二次的，是凸函数。

#### 岭回归

岭回归是线性回归的一种正则化变体，它通过在损失函数中添加L2正则化项来防止过拟合。

**优化问题**：岭回归的优化问题可以表示为：

$$\min_{w, b} \frac{1}{n} \sum_{i=1}^n (w^T x_i + b - y_i)^2 + \lambda \lVert w \rVert_2^2$$

其中 $\lambda > 0$ 是正则化参数，控制正则化强度。

这仍然是一个凸优化问题，因为目标函数是二次的，是凸函数。

### 7.1.2 逻辑回归

逻辑回归是一种用于分类问题的监督学习算法，它通过 sigmoid 函数将线性模型的输出映射到 [0, 1] 区间，表示样本属于正类的概率。

**问题形式**：给定训练数据 $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$，其中 $x_i \in \mathbb{R}^d$ 是输入特征，$y_i \in \{0, 1\}$ 是二分类标签，我们希望找到参数 $w \in \mathbb{R}^d$ 和 $b \in \mathbb{R}$，使得模型能够最好地预测样本的类别。

**模型**：逻辑回归模型为：

$$p(y=1|x) = \sigma(w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}$$

**损失函数**：逻辑回归使用对数损失函数（也称为交叉熵损失）：

$$L(w, b) = -\frac{1}{n} \sum_{i=1}^n [y_i \log \sigma(w^T x_i + b) + (1 - y_i) \log (1 - \sigma(w^T x_i + b))]$$

**优化问题**：逻辑回归的优化问题可以表示为：

$$\min_{w, b} -\frac{1}{n} \sum_{i=1}^n [y_i \log \sigma(w^T x_i + b) + (1 - y_i) \log (1 - \sigma(w^T x_i + b))]$$

这是一个凸优化问题，因为对数损失函数是凸函数。

### 7.1.3 支持向量机

支持向量机（SVM）是一种强大的分类算法，它通过寻找最大间隔超平面来分离不同类别的样本。

#### 线性支持向量机

**问题形式**：给定训练数据 $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$，其中 $x_i \in \mathbb{R}^d$ 是输入特征，$y_i \in \{-1, 1\}$ 是二分类标签，我们希望找到参数 $w \in \mathbb{R}^d$ 和 $b \in \mathbb{R}$，使得超平面 $w^T x + b = 0$ 能够最好地分离不同类别的样本。

**优化问题**：线性支持向量机的优化问题可以表示为：

$$\min_{w, b} \frac{1}{2} \lVert w \rVert_2^2$$

$$\text{s.t. } y_i (w^T x_i + b) \geq 1, \quad i=1,2,\ldots,n$$

这是一个凸优化问题，因为目标函数是二次的，是凸函数，约束是线性的。

#### 软间隔支持向量机

当训练数据线性不可分时，我们引入松弛变量来允许一些样本违反间隔约束：

$$\min_{w, b, \xi} \frac{1}{2} \lVert w \rVert_2^2 + C \sum_{i=1}^n \xi_i$$

$$\text{s.t. } y_i (w^T x_i + b) \geq 1 - \xi_i, \quad i=1,2,\ldots,n$$

$$\xi_i \geq 0, \quad i=1,2,\ldots,n$$

其中 $C > 0$ 是惩罚参数，控制对违反约束样本的惩罚强度。这仍然是一个凸优化问题。

### 7.1.4 神经网络训练中的优化问题

神经网络是一种强大的机器学习模型，其训练过程本质上是一个非凸优化问题。然而，在实际应用中，我们通常使用梯度下降法及其变体来求解。

**问题形式**：给定训练数据 $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$，我们希望找到神经网络的参数 $\theta$，使得损失函数最小化。

**损失函数**：神经网络的损失函数通常是交叉熵损失或均方误差损失：

$$L(\theta) = \frac{1}{n} \sum_{i=1}^n l(f(x_i; \theta), y_i)$$

其中 $f(x; \theta)$ 是神经网络的输出，$l$ 是损失函数。

**优化方法**：神经网络训练通常使用随机梯度下降（SGD）、Adam、RMSprop等一阶优化算法。虽然这些算法不能保证找到全局最优解，但在实践中通常能够找到足够好的局部最优解。

## 7.2 信号处理中的应用

凸优化在信号处理中有广泛的应用，特别是在信号恢复、滤波器设计和压缩感知等领域。

### 7.2.1 稀疏信号恢复

稀疏信号恢复是指从观测数据中恢复出稀疏信号的过程，这在许多信号处理应用中都非常重要。

**问题形式**：假设我们观测到的数据 $y \in \mathbb{R}^m$ 与稀疏信号 $x \in \mathbb{R}^n$ 之间的关系为 $y = Ax + e$，其中 $A \in \mathbb{R}^{m \times n}$ 是观测矩阵，$e \in \mathbb{R}^m$ 是噪声。我们希望从 $y$ 中恢复出稀疏信号 $x$。

**优化问题**：稀疏信号恢复可以建模为L1正则化优化问题（也称为LASSO）：

$$\min_{x} \frac{1}{2} \lVert y - Ax \rVert_2^2 + \lambda \lVert x \rVert_1$$

其中 $\lambda > 0$ 是正则化参数，控制信号的稀疏程度。这是一个凸优化问题，因为L1范数是凸函数。

### 7.2.2 滤波器设计

滤波器设计是信号处理中的基本问题，它涉及到设计一个滤波器来实现特定的频率响应。

#### FIR滤波器设计

有限脉冲响应（FIR）滤波器是一种常用的数字滤波器，其设计问题可以建模为凸优化问题。

**问题形式**：我们希望设计一个FIR滤波器 $h \in \mathbb{R}^N$，使其频率响应 $H(\omega) = \sum_{n=0}^{N-1} h(n) e^{-j\omega n}$ 尽可能接近理想频率响应 $H_d(\omega)$。

**优化问题**：FIR滤波器设计可以建模为最小二乘优化问题：

$$\min_{h} \int_{0}^{\pi} |H(\omega) - H_d(\omega)|^2 d\omega$$

这是一个凸优化问题，因为目标函数是关于 $h$ 的二次函数。

### 7.2.3 压缩感知

压缩感知是一种新兴的信号处理技术，它允许从少量观测数据中恢复出高维信号，前提是信号是稀疏的。

**问题形式**：假设信号 $x \in \mathbb{R}^n$ 在某个基下是稀疏的，我们通过线性测量 $y = Ax$ 来观测信号，其中 $A \in \mathbb{R}^{m \times n}$ 是测量矩阵，$m \ll n$。我们希望从 $y$ 中恢复出 $x$。

**优化问题**：压缩感知的优化问题可以建模为：

$$\min_{x} \lVert x \rVert_1$$

$$\text{s.t. } Ax = y$$

这是一个凸优化问题，因为L1范数是凸函数，约束是线性的。

## 7.3 控制系统中的应用

凸优化在控制系统中也有重要的应用，特别是在鲁棒控制、模型预测控制和最优控制等领域。

### 7.3.1 线性二次调节器

线性二次调节器（LQR）是一种经典的最优控制方法，它通过最小化二次性能指标来设计控制器。

**问题形式**：考虑线性时不变系统 $\dot{x}(t) = Ax(t) + Bu(t)$，其中 $x(t) \in \mathbb{R}^n$ 是状态向量，$u(t) \in \mathbb{R}^m$ 是控制输入，$A \in \mathbb{R}^{n \times n}$ 和 $B \in \mathbb{R}^{n \times m}$ 是系统矩阵。我们希望设计一个状态反馈控制器 $u(t) = Kx(t)$，使得闭环系统稳定，并且性能指标最小化。

**性能指标**：LQR的性能指标为：

$$J = \int_0^{\infty} (x(t)^T Q x(t) + u(t)^T R u(t)) dt$$

其中 $Q \succeq 0$ 和 $R \succ 0$ 是权重矩阵。

**优化问题**：LQR的优化问题可以转化为求解代数Riccati方程：

$$A^T P + PA - PBR^{-1}B^T P + Q = 0$$

其中 $P \succeq 0$ 是对称半正定矩阵。最优控制器增益为 $K = -R^{-1}B^T P$。

### 7.3.2 模型预测控制

模型预测控制（MPC）是一种先进的控制方法，它通过在线求解优化问题来获得控制输入。

**问题形式**：考虑离散时间线性系统 $x(k+1) = Ax(k) + Bu(k)$，其中 $x(k) \in \mathbb{R}^n$ 是状态向量，$u(k) \in \mathbb{R}^m$ 是控制输入。我们希望设计一个控制器，使得系统跟踪参考信号 $r(k)$，同时满足输入和状态约束。

**优化问题**：MPC的优化问题可以表示为：

$$\min_{u(k), u(k+1), \ldots, u(k+N-1)} \sum_{i=0}^{N-1} (x(k+i|k) - r(k+i))^T Q (x(k+i|k) - r(k+i)) + u(k+i)^T R u(k+i) + (x(k+N|k) - r(k+N))^T P (x(k+N|k) - r(k+N))$$

$$\text{s.t. } x(k+i+1|k) = Ax(k+i|k) + Bu(k+i), \quad i=0,1,\ldots,N-1$$

$$x(k|k) = x(k)$$

$$u_{min} \leq u(k+i) \leq u_{max}, \quad i=0,1,\ldots,N-1$$

$$x_{min} \leq x(k+i|k) \leq x_{max}, \quad i=1,2,\ldots,N$$

其中 $N$ 是预测 horizon，$P$ 是终端权重矩阵。这是一个凸优化问题，因为目标函数是二次的，约束是线性的。

### 7.3.3 鲁棒控制

鲁棒控制是一种考虑系统不确定性的控制方法，它通过凸优化来设计鲁棒控制器。

**问题形式**：考虑存在不确定性的线性系统 $\dot{x}(t) = (A + \Delta A)x(t) + (B + \Delta B)u(t)$，其中 $\Delta A$ 和 $\Delta B$ 是范数有界的不确定性。我们希望设计一个控制器，使得闭环系统对于所有允许的不确定性都稳定。

**优化问题**：鲁棒控制的优化问题通常可以转化为线性矩阵不等式（LMI）问题，这是一种凸优化问题。例如，线性矩阵不等式可以表示为：

$$A^T P + PA + B^T P + P B + Q < 0$$

其中 $P \succ 0$ 和 $Q \succ 0$ 是决策变量。

## 7.4 金融中的应用

凸优化在金融中有广泛的应用，特别是在投资组合优化、风险管理和期权定价等领域。

### 7.4.1 投资组合优化

投资组合优化是金融中的经典问题，它涉及到如何选择资产组合以最大化收益并最小化风险。

**问题形式**：假设我们有 $n$ 种资产，其预期收益率为 $r \in \mathbb{R}^n$，协方差矩阵为 $\Sigma \in \mathbb{S}^n_+$。我们希望选择资产权重 $w \in \mathbb{R}^n$，使得投资组合的预期收益率最大化，同时风险（方差）不超过某个阈值。

**优化问题**：投资组合优化可以建模为：

$$\max_{w} r^T w$$

$$\text{s.t. } w^T \Sigma w \leq \sigma^2$$

$$\sum_{i=1}^n w_i = 1$$

$$w_i \geq 0, \quad i=1,2,\ldots,n$$

其中 $\sigma^2$ 是风险阈值。这是一个凸优化问题，因为目标函数是线性的，约束是凸的。

### 7.4.2 风险管理

风险管理是金融中的重要问题，它涉及到评估和控制金融风险。

#### Value-at-Risk (VaR) 优化

Value-at-Risk (VaR) 是一种常用的风险度量，它表示在一定的置信水平下，投资组合在未来一段时间内可能遭受的最大损失。

**问题形式**：我们希望设计一个投资组合，使得其VaR不超过某个阈值，同时预期收益率最大化。

**优化问题**：VaR优化可以建模为：

$$\max_{w} r^T w$$

$$\text{s.t. } \text{VaR}_\alpha(w) \leq V$$

$$\sum_{i=1}^n w_i = 1$$

$$w_i \geq 0, \quad i=1,2,\ldots,n$$

其中 $\alpha$ 是置信水平，$V$ 是VaR阈值。当资产收益率服从正态分布时，VaR可以表示为 $\text{VaR}_\alpha(w) = -r^T w + z_\alpha \sqrt{w^T \Sigma w}$，其中 $z_\alpha$ 是标准正态分布的上 $\alpha$ 分位数。此时，VaR优化问题是凸的。

### 7.4.3 期权定价中的优化问题

期权定价是金融中的重要问题，它涉及到确定期权的合理价格。

#### 套利定价

套利定价理论（APT）是一种期权定价方法，它基于无套利假设。

**问题形式**：假设我们有 $n$ 种风险资产和一种无风险资产，以及 $m$ 种期权。我们希望确定期权的价格，使得不存在套利机会。

**优化问题**：套利定价可以建模为线性规划问题：

$$\min_{\theta} 0$$

$$\text{s.t. } A\theta \geq 0$$

$$c^T \theta < 0$$

其中 $\theta$ 是资产组合权重，$A$ 是资产收益率矩阵，$c$ 是资产价格向量。如果该问题无解，则不存在套利机会，期权价格是合理的。

## 7.5 小结

本章介绍了凸优化在各个领域的应用案例，包括：

1. **机器学习中的应用**：
   - 线性回归与岭回归：拟合线性模型来预测连续值输出。
   - 逻辑回归：用于二分类问题的监督学习算法。
   - 支持向量机：通过寻找最大间隔超平面来分离不同类别的样本。
   - 神经网络训练：虽然是非凸优化问题，但使用一阶方法求解。

2. **信号处理中的应用**：
   - 稀疏信号恢复：从观测数据中恢复出稀疏信号。
   - 滤波器设计：设计滤波器来实现特定的频率响应。
   - 压缩感知：从少量观测数据中恢复出高维稀疏信号。

3. **控制系统中的应用**：
   - 线性二次调节器：通过最小化二次性能指标来设计控制器。
   - 模型预测控制：通过在线求解优化问题来获得控制输入。
   - 鲁棒控制：考虑系统不确定性的控制方法。

4. **金融中的应用**：
   - 投资组合优化：选择资产组合以最大化收益并最小化风险。
   - 风险管理：评估和控制金融风险，如Value-at-Risk优化。
   - 期权定价：确定期权的合理价格，基于无套利假设。

这些应用案例展示了凸优化在解决实际问题中的强大能力。通过将实际问题建模为凸优化问题，我们可以利用成熟的凸优化算法来高效地求解，从而得到最优或近似最优的解决方案。

在下一章中，我们将介绍凸优化的软件工具和参考资料，以帮助读者更好地应用凸优化技术。

## 习题

### 基础题

**习题7.1**：使用线性回归模型拟合以下数据：

| x | y |
|---|---|
| 1 | 2 |
| 2 | 4 |
| 3 | 5 |
| 4 | 7 |
| 5 | 8 |

**习题7.2**：简述线性回归模型的基本思想和求解方法。

**习题7.3**：使用最小二乘法求解线性回归模型的参数。

### 中等题

**习题7.4**：使用线性回归模型拟合以下数据，并计算均方误差：

| x1 | x2 | y |
|----|----|---|
| 1  | 2  | 3 |
| 2  | 4  | 5 |
| 3  | 6  | 7 |
| 4  | 8  | 9 |
| 5  | 10 | 11 |

**习题7.5**：简述岭回归和LASSO回归的基本思想和区别。

**习题7.6**：使用Python实现线性回归模型，拟合习题7.1中的数据，并绘制拟合直线。

习题解答[点击这里](docs/quiz/exercise_solutions.md)